{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Exploring Generative Capabilities of Diffusion-Based Deep Generative Models <br><br> COMP3547 Deep Learning Assignment 2022/2023</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work based on several sources. Below are the most important attributions:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [2020, Denoising Diffusion Probabilistic Models (Ho, Jain, Abbeel)](https://arxiv.org/pdf/2006.11239.pdf)\n",
    "\n",
    "* [2021, Improved Denoising Diffusion Probabilistic Models (Nichol, Dhariwal)](https://proceedings.mlr.press/v139/nichol21a/nichol21a.pdf)\n",
    "\n",
    "* [2021, Diffusion Models Beat GANs on Image Synthesis (Dhariwal, Nichol)](https://arxiv.org/pdf/2105.05233v4.pdf)\n",
    "\n",
    "<br>\n",
    "\n",
    "* [2019, Generative Modeling by Estimating Gradients of the Data Distribution (Song, Ermon)](https://proceedings.neurips.cc/paper/2019/file/3001ef257407d5a371a96dcd947c7d93-Paper.pdf)\n",
    "\n",
    "* [2020, Score-based Generative Modeling Through Stochastic Differential Equations (Song, Sohl-Dickstein, Kingma, Kumar, Ermon, Poole)](https://arxiv.org/pdf/2011.13456.pdf)\n",
    "\n",
    "* [2020, Improved Techniques for Training Score-based Generative Models (Song, Ermon)](https://proceedings.neurips.cc/paper/2020/file/92c3b916311a5517d9290576e3ea37ad-Paper.pdf)\n",
    "\n",
    "* [2020, Denoising Diffusion Implicit Models (Song, Meng, Ermon)](https://arxiv.org/pdf/2010.02502.pdf)\n",
    "\n",
    "\n",
    "* [2022, High-Resolution Image Synthesis with (Rombach, Blattmann, Lorenz, Esser, Ommer)](https://arxiv.org/pdf/2112.10752.pdf)\n",
    "\n",
    "* [2022, Diffusion Models: A Comprehensive Survey of Methods and Applications (Yang et al.)](https://arxiv.org/abs/2209.00796)\n",
    "\n",
    "\n",
    "* [2022, How Much is Enough? A Study on Diffusion Times in Score-based Generative Models (Franzese et al.)](https://arxiv.org/abs/2206.05173)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [https://github.com/dome272/Diffusion-Models-pytorch (Apache License 2.0)](https://github.com/dome272/Diffusion-Models-pytorch)\n",
    "\n",
    "* [https://colab.research.google.com/drive/1sjy9odlSSy0RBVgMTgP7s99NXsqglsUL?usp=sharing (MIT License)](https://colab.research.google.com/drive/1sjy9odlSSy0RBVgMTgP7s99NXsqglsUL?usp=sharing)\n",
    "\n",
    "* [https://github.com/lucidrains/denoising-diffusion-pytorch (MIT License)](https://github.com/lucidrains/denoising-diffusion-pytorch)\n",
    "\n",
    "* [https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=3a159023 (No license information)](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=3a159023)\n",
    "\n",
    "* [https://github.com/labmlai (MIT License)](https://github.com/labmlai)\n",
    "\n",
    "* [https://github.com/heejkoo/Awesome-Diffusion-Models (MIT License)](https://github.com/heejkoo/Awesome-Diffusion-Models)\n",
    "\n",
    "* [https://github.com/yang-song/score_sde (Apache License 2.0)](https://github.com/yang-song/score_sde)\n",
    "\n",
    "* [https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing#scrollTo=XCR6m0HjWGVV (Apache License 2.0)](https://colab.research.google.com/drive/120kYYBOVa1i0TD85RjlEkFjaWDxSFUx3?usp=sharing#scrollTo=XCR6m0HjWGVV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import diffusion\n",
    "import dataset\n",
    "import config\n",
    "\n",
    "import tqdm\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(config.SEED)\n",
    "torch.cuda.manual_seed_all(config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = dataset.get_data(config.DATASET_NAME, config.BATCH_SIZE)\n",
    "\n",
    "model = model.EpsilonTheta(\n",
    "    channels=config.CHANNELS,\n",
    "    feature_map_size=config.FEATURE_MAP_SIZE,\n",
    "    groups_number=config.GROUPS_NUMBER,\n",
    "    heads_number=config.HEADS_NUMBER,\n",
    "    blocks_number=config.BLOCKS_NUMBER,\n",
    ").to(config.DEVICE)\n",
    "\n",
    "diffusion = diffusion.DenoisingDiffusion(\n",
    "    epsilon_theta_model=model,\n",
    "    beta_initial=config.BETA_INITIAL,\n",
    "    beta_final=config.BETA_FINAL,\n",
    "    T=config.T,\n",
    "    device=config.DEVICE\n",
    ")\n",
    "\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.CHECKPOINT_FILE is not None:\n",
    "    checkpoint = torch.load(config.CHECKPOINT_FILE)\n",
    "    epoch_start = checkpoint[\"epoch\"]\n",
    "    loss = checkpoint[\"loss\"]\n",
    "    losses = checkpoint[\"losses\"]\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    optimiser.load_state_dict(checkpoint[\"optimiser_state_dict\"])\n",
    "else:\n",
    "    epoch_start = 1\n",
    "    losses = []\n",
    "    \n",
    "if epoch_start > config.EPOCHS:\n",
    "    raise ValueError(\"Invalid number of epochs. Please choose a number greater than the number of epochs already trained.\")\n",
    "\n",
    "    \n",
    "for epoch in range(epoch_start, config.EPOCHS + 1):\n",
    "    print(f\"EPOCH {epoch}/{config.EPOCHS}\")\n",
    "    epoch_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm.tqdm(data_loader, desc=\"Processing batches\"):\n",
    "        \n",
    "        # Load a batch of data and assign it to device\n",
    "        x_0 = batch[0].to(config.DEVICE)\n",
    "        \n",
    "        # Get random t for each sample in the batch\n",
    "        t = torch.randint(0, config.T, (config.BATCH_SIZE,), device=config.DEVICE, dtype=torch.long)\n",
    "        \n",
    "        # Sample noise from the Normal Distribution \n",
    "        epsilon = torch.randn_like(x_0)\n",
    "           \n",
    "        # Sample $x_t$ for $q(x_t|x_0)$\n",
    "        x_t = diffusion.forward_diffusion(x_0, t, epsilon)\n",
    "        \n",
    "        # Get \\{\\epsilon_\\theta}(\\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t}\\epsilon, t)\n",
    "        epsilon_theta = diffusion.epsilon_theta_model(x_t, t)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = torch.functional.F.mse_loss(epsilon, epsilon_theta)\n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate and step the optimiser\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "    # Collect losses for plottings\n",
    "    epoch_loss /= len(data_loader)\n",
    "    losses.append(epoch_loss)\n",
    "            \n",
    "    # Sample new data\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # x_T \\sim p(x_T) = \\mathcal{N}(x_T; \\mathbf{0}, \\mathbf{I})\n",
    "        x_T = torch.randn(\n",
    "            [64, config.CHANNELS, config.IMAGE_SIZE, config.IMAGE_SIZE], \n",
    "            device=config.DEVICE\n",
    "        )\n",
    "\n",
    "        # Remove noise in T steps\n",
    "        for t_ in tqdm(range(0, config.ET_T), desc=\"Denoising timesteps\"):\n",
    "            t = config.ET_T - t_ - 1\n",
    "\n",
    "            # Sample {p_\\theta}(x_{t-1}|x_t) \n",
    "            x_T = diffusion.reverse_diffusion(x_T, x_T.new_full((64, ), t, dtype=torch.long))\n",
    "\n",
    "        # Display the data\n",
    "        model.diffusion.display_images(x_T)\n",
    "        \n",
    "    # Print mean loss at the end of epoch\n",
    "    print(f\"Epoch mean loss: {epoch_loss}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    # Save progress (checkpoint) every `config.CHECKPOINT_FREQUENCY` epochs\n",
    "    if epoch % config.CHECKPOINT_FREQUENCY == 0:\n",
    "         torch.save({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"loss\": loss,\n",
    "                \"losses\": losses,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimiser_state_dict\": optimiser.state_dict()\n",
    "            }, f\"ddpm_{config.DATASET_NAME}_checkpoint_epoch_{epoch}.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
